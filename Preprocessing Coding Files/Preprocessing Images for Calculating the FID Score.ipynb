{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "929f0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cebbfc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps copy.png'\n",
    "final_path = '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c0a81a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d64ec936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_images_to_2_rows(file_path, output_folder):\n",
    "\n",
    "    with Image.open(file_path) as img:\n",
    "        image_width, image_height = img.size\n",
    "        # Since there are 8 images per row and 2 rows\n",
    "        single_image_width = image_width // 8\n",
    "        single_image_height = image_height // 2\n",
    "        \n",
    "        images = []\n",
    "        for row in range(2):  # two rows\n",
    "            for col in range(8):  # eight images per row\n",
    "                left = col * single_image_width\n",
    "                top = row * single_image_height\n",
    "                right = (col + 1) * single_image_width\n",
    "                bottom = (row + 1) * single_image_height\n",
    "                crop = img.crop((left, top, right, bottom))\n",
    "                crop_path = f\"{output_folder}/image_row{row}_col{col}.png\"\n",
    "                crop.save(crop_path)\n",
    "                images.append(crop_path)\n",
    "                \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b10a2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row0_col0.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row0_col1.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row0_col2.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row0_col3.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row0_col4.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row0_col5.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row0_col6.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row0_col7.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row1_col0.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row1_col1.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row1_col2.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row1_col3.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row1_col4.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row1_col5.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row1_col6.png',\n",
       " '/Users/karthik/Desktop/PROCESS/1by4_Basic_GAN_200-eps//image_row1_col7.png']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_images_to_2_rows(image_path, final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd012ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0426e650",
   "metadata": {},
   "source": [
    "**Cropping Images for 2 rows & 8 columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bece5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def crop_image(image_path, output_folder, num_cols=8, num_rows=2):\n",
    "\n",
    "    with Image.open(image_path) as img:\n",
    "        image_width, image_height = img.size\n",
    "        single_image_width = image_width // num_cols\n",
    "        single_image_height = image_height // num_rows\n",
    "\n",
    "        # Create a new directory for the cropped images\n",
    "        base_name = os.path.basename(image_path)\n",
    "        name, ext = os.path.splitext(base_name)\n",
    "        image_output_folder = os.path.join(output_folder, name)\n",
    "        if not os.path.exists(image_output_folder):\n",
    "            os.makedirs(image_output_folder)\n",
    "\n",
    "        # Crop and save the images\n",
    "        for row in range(num_rows):\n",
    "            for col in range(num_cols):\n",
    "                left = col * single_image_width\n",
    "                top = row * single_image_height\n",
    "                right = (col + 1) * single_image_width\n",
    "                bottom = (row + 1) * single_image_height\n",
    "                crop = img.crop((left, top, right, bottom))\n",
    "                crop_path = os.path.join(image_output_folder, f\"{name}_row{row}_col{col}{ext}\")\n",
    "                crop.save(crop_path)\n",
    "\n",
    "def process_images_in_directory(directory_path, output_folder):\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            crop_image(image_path, output_folder)\n",
    "\n",
    "# Set the correct paths\n",
    "directory_path = '/Users/karthik/Desktop/PROCESS/'\n",
    "output_folder = '/Users/karthik/Desktop/PROCESS/Cropped/'\n",
    "\n",
    "# Process all images in the directory\n",
    "process_images_in_directory(directory_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52277cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9a0a6ad",
   "metadata": {},
   "source": [
    "**Cropping Images for 4 row & 4 column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "688a0206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def crop_image(image_path, output_folder, num_cols, num_rows):\n",
    "\n",
    "    with Image.open(image_path) as img:\n",
    "        image_width, image_height = img.size\n",
    "        single_image_width = image_width // num_cols\n",
    "        single_image_height = image_height // num_rows\n",
    "\n",
    "        # Create a new directory for the cropped images\n",
    "        base_name = os.path.basename(image_path)\n",
    "        name, ext = os.path.splitext(base_name)\n",
    "        image_output_folder = os.path.join(output_folder, name)\n",
    "        if not os.path.exists(image_output_folder):\n",
    "            os.makedirs(image_output_folder)\n",
    "\n",
    "        # Crop and save the images\n",
    "        for row in range(num_rows):\n",
    "            for col in range(num_cols):\n",
    "                left = col * single_image_width\n",
    "                top = row * single_image_height\n",
    "                right = (col + 1) * single_image_width\n",
    "                bottom = (row + 1) * single_image_height\n",
    "                crop = img.crop((left, top, right, bottom))\n",
    "                crop_path = os.path.join(image_output_folder, f\"{name}_row{row}_col{col}{ext}\")\n",
    "                crop.save(crop_path)\n",
    "\n",
    "def process_images_in_directory(directory_path, output_folder, num_cols, num_rows):\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            crop_image(image_path, output_folder, num_cols, num_rows)\n",
    "\n",
    "# Set the correct paths\n",
    "directory_path = '/Users/karthik/Desktop/PROCESS/'\n",
    "output_folder = '/Users/karthik/Desktop/PROCESS/Cropped/'\n",
    "\n",
    "# Parameters for cropping (number of columns and rows)\n",
    "num_cols = 4\n",
    "num_rows = 4\n",
    "\n",
    "# Process all images in the directory with the specified number of columns and rows\n",
    "process_images_in_directory(directory_path, output_folder, num_cols, num_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba6cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a44cd43d",
   "metadata": {},
   "source": [
    "Preparing for FID SCORE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e167bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import inception_v3\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def get_inception_features(images, model, batch_size=32):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    \n",
    "    # Transform input images to match Inception's expectations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    for img_path in images:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "        with torch.no_grad():\n",
    "            pred = model(img)\n",
    "        features.append(pred.squeeze(0).cpu().numpy())\n",
    "        \n",
    "    features = np.array(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f4c9e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid(real_features, gen_features):\n",
    "    mu1, sigma1 = real_features.mean(axis=0), np.cov(real_features, rowvar=False)\n",
    "    mu2, sigma2 = gen_features.mean(axis=0), np.cov(gen_features, rowvar=False)\n",
    "    \n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    \n",
    "    # Check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    \n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd7fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22d679f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karthik/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/karthik/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /Users/karthik/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100%|████████████████████████████████████████| 104M/104M [00:05<00:00, 20.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "inception_model = inception_v3(pretrained=True)\n",
    "inception_model.fc = torch.nn.Identity()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b98352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eda68d8a",
   "metadata": {},
   "source": [
    "<H3>CALCULATING FID SCORE FOR Vanilla GAN Generated Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6375bf4",
   "metadata": {},
   "source": [
    "**Vanilla GANs 4 Layer   Eps = 200**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "608760eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Assuming you have a directory with real images and another with generated images\n",
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/Vanilla_GANs/Vanilla_GAN_with_4_Layers/VG-4Layers-200eps/'\n",
    "\n",
    "# List the paths to the real images\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "# Make sure there are 2176 real images\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "# List the paths to the generated images\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "# Make sure there are 16 generated images\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cab473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9f7c0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 496.7845755492306\n"
     ]
    }
   ],
   "source": [
    "# Calculate features\n",
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "# Calculate FID\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c88402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43929e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e844388",
   "metadata": {},
   "source": [
    "**Vanilla GANs 4 Layer   Eps = 250**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93beafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/Vanilla_GANs/Vanilla_GAN_with_4_Layers/VG-4Layer-250eps/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a78f92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47a05be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 497.99034096661757\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573d297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3669294a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "426f7bbf",
   "metadata": {},
   "source": [
    "**Vanilla GANs 4 Layer   lr-0.0002 - 200 Eps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08fd97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/Vanilla_GANs/Vanilla_GAN_with_4_Layers/VG-4Layers-lr-0.0002-200eps/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f546f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01dc5037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 488.18345876653063\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a3db90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c9ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a958460b",
   "metadata": {},
   "source": [
    "**1 by 4 - Vanilla GANs - 4Layers - 200eps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a079e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/Vanilla_GANs/Vanilla_GAN_with_4_Layers/1by4-VG-4Layers-200eps/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1ebc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "120b5b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 422.98492524014284\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048775e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18ea99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3cffd6c",
   "metadata": {},
   "source": [
    "**1 by 4 - Vanilla GANs- 64X64 - 200 Eps - lr = 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "425acbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/Vanilla_GANs/Vanilla_GAN_with_4_Layers/1by4-VG-64X64-200eps-lr_2/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "133317b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 419.21803184852365\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42952851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee9b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68172c1c",
   "metadata": {},
   "source": [
    "**1 by 4 - Vanilla GANs- 64X64 - 200 Eps - lr = 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec9064e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/Vanilla_GANs/Vanilla_GAN_with_4_Layers/1by4-VG-64X64-200eps-lr_3/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b93488c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 427.8725253176444\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96496a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b70ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e964e83e",
   "metadata": {},
   "source": [
    "**2 by 2 Vanilla-GAN - Increased Sample - 2 by 2 Resized and Rotated Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "19c84abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/FiguresStacked-2X2/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/Vanilla_GANs/Increased-Sample/2by2-VG-Increased-Sample/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c694b6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 478.16585930439976\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a542e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6750da51",
   "metadata": {},
   "source": [
    "**4 by 4 Vanilla-GAN - Increased Sample - 4 by 4 Resized and Rotated Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c2b3b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/Vanilla_GANs/Increased-Sample/Vanilla-GAN-4by4-Increased-Sample/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e709cc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 448.3321029119707\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8d5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d93ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41b203d3",
   "metadata": {},
   "source": [
    "<H3>CALCULATING FID SCORE FOR C-GAN Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685c4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1bca62d",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 4 Layer G & D - BCE Loss - eps = 250 Z_dim = 112**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d223d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_4_Layers_BCE_Loss/C-GAN-using-ANN-4-Layer-G&D-BCELoss- eps-250Z_dim-112/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8f61a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 507.7035363649482\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfbe6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0456b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f23913df",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 4 Layer G & D BCE Loss EPS = 200**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f216821",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_4_Layers_BCE_Loss/C-GAN-using-ANN-4-Layer-G&D-BCELoss-200 EPS/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee8ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 474.7411320123402\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4bbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf227a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb3e1220",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 4 Layer G & D BCE Loss EPS = 250**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4dfa348",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_4_Layers_BCE_Loss/C-GAN-using-ANN-4-Layer-G&D-BCELoss-250-EPS/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff1f95f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 509.0256116218969\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26653a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474559dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94bab0a5",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 4 Layer G & D BCE Loss Eps = 200 Z_dim = 112**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11bce34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_4_Layers_BCE_Loss/C-GAN-using-ANN-4-Layer-G&D-BCELoss-eps-200Z_dim-112/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23e9ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 502.98547592438734\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11763a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3e25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90ad90e0",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 5 Layer G & D BCELoss - Eps = 200 - z_dim = 112 TUNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00e98f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_5_Layers_BCE_Loss/C-GAN-using-ANN-5-Layer-G&D-BCELoss- eps200-z_dim -112TUNING/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f76c7682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 509.50546782793595\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d31b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1912147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cae9477a",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 5 Layer G & D - BCELoss - Eps = 200 - z_dim = 112**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb476fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_5_Layers_BCE_Loss/C-GAN-using-ANN-5-Layer-G&D-BCELoss-eps200-z_dim-112/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a4cbf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 499.2763402028513\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058aee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad4ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d96fb29",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 5 Layer G & D BCELoss Eps = 250 - z_dim = 112**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28591579",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_5_Layers_BCE_Loss/C-GAN-using-ANN-5-Layer-G&D-BCELoss-eps250-z_dim-112/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea9b75a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 512.1563970357131\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3557387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22df62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb784983",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 5 Layer G with BN of 3Layers BCELoss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "796d9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_5_Layers_BCE_Loss/C-GAN-using-ANN-5-Layer-G-with-BN-of-3Layers-BCELoss/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b430f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 546.3369696526111\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b3ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c60af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1333a31",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 5 Layer G & D BCELoss - EPS = 250**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd58a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_5_Layers_BCE_Loss/C-GAN_using_ANN_5_Layer_G&D-BCELoss-250EPS/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3134f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 521.9359131127594\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a548ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda66748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9210d17a",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 5 Layer G with BN of 3 Layers BCEWithLogitsLoss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2ffa1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_5_Layers_BCE_Loss/C-GAN_using_ANN_5_Layer_G_with_BN_of_3_Layers-BCEWithLogitsLoss/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b054e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 534.0923662798457\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb388f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e1453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33d61981",
   "metadata": {},
   "source": [
    "**C-GAN using ANN with 5 Layer G with BN of 1Layers MSELoss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55fc2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_MSE_Loss/C-GAN_using-ANN-5-Layer-G-with-BN-of-1Layers-MSELoss/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dd9a64ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 488.8694451641635\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0154d00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbccdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753b549e",
   "metadata": {},
   "source": [
    "**C-GAN using ANN with 5 Layer G with BN of 2Layers MSELoss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09c24d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_MSE_Loss/C-GAN_using-ANN-5-Layer-G-with-BN-of-2-Layers -MSELoss/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17b38c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 490.8425120849204\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6d1b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd2896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca442491",
   "metadata": {},
   "source": [
    "**C-GAN using ANN with 5 Layer G with BN of 3 Layers MSELoss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "038c368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_MSE_Loss/C-GAN_using-ANN-5-Layer-G-with-BN-of-3-Layers -MSELoss/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "738f957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 491.61758050569006\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1851d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637e37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d33b5cb",
   "metadata": {},
   "source": [
    "**C-GAN using ANN with 5 Layer G with No BN Layers MSELoss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc2cda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_MSE_Loss/C-GAN_using_ANN_5_Layer_G D_with_NO_BN_Layers-MSE Loss/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ba5b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 531.6132213796026\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fd132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73285d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40f83da4",
   "metadata": {},
   "source": [
    "**C-GAN using ANN with 5 Layer G with BN of 1Layers MSELoss Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2b33aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_MSE_Loss/C-GANusingANN5-Layer-G-with-BN-of-2-Layers-MSELoss-TUNING/**C-GAN using ANN with 5 Layer G with BN of 1Layers MSELoss**'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98b72e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 491.2249674784682\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8e394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f9ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d547ac6",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 6 Layer G & 5 layer D - BCELoss - Eps = 200 - z_dim = 112**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e88a16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_6_Layers/C-GANusingANN-6-Layer-G&5layerD-BCELoss-eps200-z_dim-112/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "14b4f91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 481.02084647738286\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5441c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac172d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bbfb605",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 6 Layer G & D - BCELoss - Eps = 200 - z_dim = 112**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f2c3868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_6_Layers/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1e1097b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 494.44503296931066\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e16fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad033e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2db93887",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 6 Layer G & D - BCELoss - Eps = 200 - z_dim = 112 Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2f3680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_6_Layers/C-GANusingANN-6-Layer-G&D-BCELoss-eps200-z_dim-112 Tuning/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "baa8488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 492.08403720514593\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a6fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca93faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d30f841d",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 7 - Layer G & 6 - layer - D - BCELoss - Eps = 250 - z_dim = 112**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0d1a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_7_Layers/C-GANusingANN-7-LayerG&6-layer-D-BCELoss-eps250-z_dim-112/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "65dea246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 502.9398728074666\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b1e471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d1c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37d7846b",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 7 - Layer G & D - BCELoss - Eps = 250 - z_dim = 112 - COMBO - 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "22f83646",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_7_Layers/C-GANusingANN-7-LayerG&D-BCELoss-eps200-z_dim-112-COMBO-2/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d534ad63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 493.31799868400844\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e090c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee34db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0e86982",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 7 - Layer G & D - BCELoss - Eps = 250 - z_dim = 112 COMBO - 1 Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "86bf9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_7_Layers/C-GANusingANN-7-LayerG&D-BCELoss-eps250-z_dim-112-COMBO-1-Tuning/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c11c75eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 516.1787562921003\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf38b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47d980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a07a45fd",
   "metadata": {},
   "source": [
    "**C-GAN using ANN 7 - Layer G & D - BCELoss - Eps = 250 - z_dim = 112 COMBO - 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c1be823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_7_Layers/C-GANusingANN-7-LayerG&D-BCELoss-eps250-z_dim-112-COMBO-1/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a3b4d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 473.150113626764\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505afed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0511ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d42de872",
   "metadata": {},
   "source": [
    "**C-GAN using ANN - 8 Layer G & D BCELoss Eps = 250 - z_dim = 112 COMBO - 2 Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6e4e2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_8_Layers/C-GAN-using-ANN-8-Layer-G&D-BCELoss- eps 250-z_dim-112COMBO-2Tuning/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "125a8ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 490.2710705366761\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec17d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48375e05",
   "metadata": {},
   "source": [
    "**C-GAN using ANN - 8 Layer G & D BCELoss Eps = 250 - z_dim = 112 COMBO - 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0b47c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_8_Layers/C-GAN_using-ANN-8-Layer-G&D-BCELoss-eps 250-z_dim-112-COMBO-2-Copy1/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "29aaa2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 480.23128042229456\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6c260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7deb8ea0",
   "metadata": {},
   "source": [
    "**C-GAN using ANN - 8 Layer G & D BCELoss Eps = 250 - z_dim = 112 COMBO - 1 Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "48d4f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_8_Layers/C-GAN_using_ANN-8-Layer-G&D-BCELoss-eps-250-z_dim-112-COMBO-1-Tuning/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2275f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 516.9741324275257\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661e8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfbe8070",
   "metadata": {},
   "source": [
    "**C-GAN using ANN - 8 - Layer - G & D - BCELoss - Eps = 250 - z_dim = 112 - COMBO-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1609cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_8_Layers/C-GAN_using_ANN-8-Layer-G&D-BCELoss-eps-250-z_dim-112-COMBO-2/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0b810749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 486.6516508494069\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7f69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b99889f",
   "metadata": {},
   "source": [
    "**C-GAN using ANN - 8 Layer - G & D - BCELoss - Eps = 250 - z_dim = 112 - COMBO - 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0929dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_8_Layers/C-GAN_using_ANN-8-Layer-G&D-BCELoss-eps250-z_dim-112-COMBO-3-Copy1/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "08d69674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 511.3109806278178\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4199d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a0408bc",
   "metadata": {},
   "source": [
    "**C-GAN using ANN - 8 Layer - G & D - BCELoss - Eps = 250 - z_dim = 112 - COMBO - 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "41649a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/C-GANs/C-GAN_8_Layers/C-GAN_using_ANN_8-Layer-G&D-BCELoss-eps 250-z_dim-112-COMBO-2-Copy2/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f18f7393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 484.149182822307\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739de07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0947f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "308548c4",
   "metadata": {},
   "source": [
    "<H3>CALCULATING FID SCORE FOR DC-GAN Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8185a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee452cb3",
   "metadata": {},
   "source": [
    "**1by4 - 128X128 Image Resolution - Residual Block - lr = 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ed7a0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/1by4-Residual-Block/1by4-128X128-Residual-Block-lr-3/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "acfefa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 306.99795392703925\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70cd7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca26e590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cbd1d20",
   "metadata": {},
   "source": [
    "**1by4 - Residual Block - Filters = 128 - EPS = 25**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9f3c5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/1by4-Residual-Block/1by4-ResBlock-128-Filters-25eps/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1bb6a62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 366.75844544403384\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a778e50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64635610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f88fe90c",
   "metadata": {},
   "source": [
    "**1by4 - Residual Block - 128X128 Image Resolution - lr = 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0977a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/1by4-Residual-Block/1by4-ResBlock-128X128-lr-2 /'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "266c3a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 368.8807606005696\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac3a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87522daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56c42041",
   "metadata": {},
   "source": [
    "**1by4 - Residual Block - Image Resolution 64X64 - 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a6b52dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/1by4-Residual-Block/1by4-ResBlock-64X64-1/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "606ed1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 339.48543465349184\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8643508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91139903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aece3951",
   "metadata": {},
   "source": [
    "**1by4 - Residual Block - Image Resolution 64X64 - 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "54990832",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/1by4-Residual-Block/1by4-ResBlock-64X64-2/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d0d8af45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 332.74480486823325\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b793ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9fa8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acb2b9e4",
   "metadata": {},
   "source": [
    "**1by4 - Residual Block - Image Resolution 64X64 - 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "db9b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/1by4-Residual-Block/1by4-ResBlock-64X64-3/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "05d2248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 339.48543486862263\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32def1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63070b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52a33a8c",
   "metadata": {},
   "source": [
    "**1 by 4 - Residual Block - Image Resolution 128X128 - Combo -1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "045d1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/1by4-Residual-Block/RB-128X128-Combo-1/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ef2955fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 314.0494195522597\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9841fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e478242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bba62260",
   "metadata": {},
   "source": [
    "**4by4 - Image Resolution - 128X128 - method - 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e5e58a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/4by4-Topo/4by4-128X128-method-1/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ac498334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 423.28431534258493\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c68fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320ce84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06e592b6",
   "metadata": {},
   "source": [
    "**4by4 - Image Resolution - 64X64**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b597ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/4by4-Topo/4by4-64x64-1/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "76803b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 448.69062650417584\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e6b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318fd69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a4d70e0",
   "metadata": {},
   "source": [
    "**4by4 - Image Resolution - 256X256**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c6d638f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/4by4-Topo/4by4-topo-DC-GAN-256X256/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a46d7b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 325.47247543368235\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c5274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d2d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0ce49ed",
   "metadata": {},
   "source": [
    "**1by4 - Image Resolution 64X64 - EPS = 25 - Batch Size = 64**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d3b08d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/Convo-Layers-with-combos/1by4-64X64-25Eps-bs-64/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3837f5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 345.446282594336\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d6220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8cdf959",
   "metadata": {},
   "source": [
    "**1by4 - EDGE Processed Topography - Kernel Degree = 6 - 64 X 64 - EPS = 25**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b4d0a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-EDGE-Topography/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/Convo-Layers-with-combos/1by4-EDGE-6-Topo-64X64-eps-25 /'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c09a12ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 273.1905145542704\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e12739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "361238d1",
   "metadata": {},
   "source": [
    "**1by4 - EDGE Processed Topography - Kernel Degree = 8 - 64 X 64 - EPS = 25**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9a3e45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-Edge-8Degree/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/DC-GANs/Convo-Layers-with-combos/1by4-EDGE-8-Topo-64X64-eps25/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5878187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 276.3324416618382\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757117f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37220b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8af5155",
   "metadata": {},
   "source": [
    "<H3>CALCULATING FID SCORE FOR Wassertein-GAN Generated Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd306460",
   "metadata": {},
   "source": [
    "**1 by 4 topo - Image Resolution 64 X 64 - lr = 3 - z_dim = 100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "475bb0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/WGAN/1by4-topo-64X64-lr-3-z_dim-100/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "67ebdf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 322.1146314623371\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a4172b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5472f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "106438ad",
   "metadata": {},
   "source": [
    "**1 by 4 - topo - Image Resolution 64 X 64 - lr = 3 - z_dim = 112 - EPS = 40**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4c9e47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/WGAN/1by4-topo-64X64-lr-3-z_dim-112-EPS-40/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "531ad31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 308.46295284788675\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d9e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cba51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a61e3e8d",
   "metadata": {},
   "source": [
    "**1 by 4 topo - Image Resolution 64 X 64 - lr = 3 - z_dim = 112**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "67056372",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/WGAN/1by4-topo-64X64-lr-3-z_dim-112/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "434ca12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 316.8117227020753\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bbb412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39183f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9afb810",
   "metadata": {},
   "source": [
    "**1 by 4 topo - Image Resolution 64 X 64 - lr = 2 - z_dim = 112 - EPS = 40**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7a8ee604",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/WGAN/1by4_topo_64X64_lr_2_z_dim_112_EPS-40/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8f03339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 306.24041750465994\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712dcbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce04c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e5bbda3",
   "metadata": {},
   "source": [
    "**1 by 4 topo - Image Resolution 64X64 - lr = 3 - z_dim = 112 - EPS = 40 - Filters = 128**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e8a49527",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/WGAN/1by4_topo_64X64_lr_3_z_dim_112_EPS-40_128Filters/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "13e1e850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 336.02679792426375\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3633ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba561f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03aa93fb",
   "metadata": {},
   "source": [
    "**1 by 4 topo - Image Resolution 64X64 - lr = 3 - z_dim = 112 - EPS = 40 - Filters = 96**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a4fe1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/WGAN/1by4_topo_64X64_lr_3_z_dim_112_EPS-40_96Filters/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3bcf95b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 353.6806062680671\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0856e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e6e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7c26398",
   "metadata": {},
   "source": [
    "**4 by 4 - Image Resolution 64 X 64 - lr = 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ddc2dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/WGAN/4by4-64X64-lr2/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0d0450e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 419.3718660064734\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc37779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c35e450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d5d5905",
   "metadata": {},
   "source": [
    "**4 by 4 - Image Resolution 64 X 64 - lr = 3 - EPS = 30**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fe6a14ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/WGAN/4by4-64X64-lr3-EPS-30/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8ddb5cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 422.73698421597624\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52e781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfe309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cf2884a",
   "metadata": {},
   "source": [
    "**4 by 4 - Image Resolution 64X64 - lr = 3 - EPS = 40 - Filter = 128**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f3d16182",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/WGAN/4by4-64X64-lr3-EPS-40-Filter-128/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d7113bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 407.6240499460357\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be7abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa95f1e9",
   "metadata": {},
   "source": [
    "**4 by 4 - Image Resolution 64X64 - lr = 3 - EPS = 40**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dd93af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images/'\n",
    "generated_images_dir = '/Users/karthik/Desktop/Preprocessing_Image_for_FID_SCORE/WGAN/4by4-64X64-lr3-EPS-40/'\n",
    "\n",
    "real_image_paths = [os.path.join(real_images_dir, image) for image in os.listdir(real_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(real_image_paths) == 2176, \"The number of real images should be 2176\"\n",
    "\n",
    "generated_image_paths = [os.path.join(generated_images_dir, image) for image in os.listdir(generated_images_dir) if image.endswith('.png')]\n",
    "\n",
    "assert len(generated_image_paths) == 16, \"The number of generated images should be 16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a02e320b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 427.8682692488611\n"
     ]
    }
   ],
   "source": [
    "real_features = get_inception_features(real_image_paths, inception_model)\n",
    "gen_features = get_inception_features(generated_image_paths, inception_model)\n",
    "\n",
    "fid_score = calculate_fid(real_features, gen_features)\n",
    "print('FID score:', fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b08fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba841451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
