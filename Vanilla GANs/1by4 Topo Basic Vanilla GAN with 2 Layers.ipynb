{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2b9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ae8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ae51b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b68d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd13d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/processed_Pattern_FeatureIdx_1005_TopoUnit_4X4.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794a53d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=192x192>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with Image.open(image_path) as img:\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486b665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ef7c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images:  2176\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/karthik/GANS/1by4-TOPO-Resized/bio_materials/'\n",
    "\n",
    "img_names = []\n",
    "\n",
    "for folder, subfolders, filenames in os.walk(path):\n",
    "    for img in filenames:\n",
    "        img_names.append(folder+ '/' +img)\n",
    "        \n",
    "print('Images: ',len(img_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959444e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de75f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sizes = []\n",
    "\n",
    "rejected = []\n",
    "\n",
    "for item in img_names:\n",
    "    try:\n",
    "        with Image.open(item) as img:\n",
    "            img_sizes.append(img.size)\n",
    "            \n",
    "    except:\n",
    "        rejected.append(item) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbaf6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c019940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2176\n"
     ]
    }
   ],
   "source": [
    "print(len(img_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a258728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f863014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(img_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bbd0061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  188  179\n",
       "1  184  188\n",
       "2  192  192\n",
       "3  192  192\n",
       "4  198  195"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa940eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2176.000000</td>\n",
       "      <td>2176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>190.460018</td>\n",
       "      <td>190.635110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.313203</td>\n",
       "      <td>5.348639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>166.000000</td>\n",
       "      <td>160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>188.000000</td>\n",
       "      <td>189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>192.000000</td>\n",
       "      <td>192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1\n",
       "count  2176.000000  2176.000000\n",
       "mean    190.460018   190.635110\n",
       "std       5.313203     5.348639\n",
       "min     166.000000   160.000000\n",
       "25%     188.000000   189.000000\n",
       "50%     192.000000   192.000000\n",
       "75%     193.000000   193.000000\n",
       "max     200.000000   200.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8e3e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694babd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1d56a02",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8e139a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 3e-4\n",
    "z_dim = 112\n",
    "image_dim = 192 * 192 * 1  # 36864, for grayscale images\n",
    "batch_size = 32\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f37052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad6e2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((192,192)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e819c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "848947a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "root = '/Users/karthik/GANS/1by4-TOPO-Resized/'\n",
    "print(os.path.exists(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d72863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "719c214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "class_dir = os.path.join(root, 'bio_materials')\n",
    "os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "for entry in os.scandir(root):\n",
    "    if entry.is_file() and entry.name.endswith('.png'):  \n",
    "        shutil.move(entry.path, class_dir)\n",
    "\n",
    "\n",
    "train_data = datasets.ImageFolder(root, transform=transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c7067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88185d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1856efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 192, 192])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cfa95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46179aed",
   "metadata": {},
   "source": [
    "**Constructing the Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1741aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb847c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "375bb9e3",
   "metadata": {},
   "source": [
    "**Contrusting the Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "066e152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(), \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a9883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee65f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(image_dim).to(device)\n",
    "gen = Generator(z_dim, image_dim).to(device)\n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "432c7af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84e683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d968a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter \n",
    "\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "step = 0\n",
    "fixed_noise = torch.randn(16, z_dim).to(device)   # 32 -> 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57ea2495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cdee30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c153426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d56476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/300] Completed - Loss D: 0.3903, loss G: 7.6952\n",
      "Epoch [4/300] Completed - Loss D: 0.0011, loss G: 7.2805\n",
      "Epoch [9/300] Completed - Loss D: 0.1443, loss G: 1.5271\n",
      "Epoch [14/300] Completed - Loss D: 0.2929, loss G: 1.3116\n",
      "Epoch [19/300] Completed - Loss D: 0.1244, loss G: 1.6836\n",
      "Epoch [24/300] Completed - Loss D: 0.2224, loss G: 1.3248\n",
      "Epoch [29/300] Completed - Loss D: 0.1357, loss G: 1.7017\n",
      "Epoch [34/300] Completed - Loss D: 0.0475, loss G: 2.6496\n",
      "Epoch [39/300] Completed - Loss D: 0.0706, loss G: 2.6170\n",
      "Epoch [44/300] Completed - Loss D: 0.2685, loss G: 2.6118\n",
      "Epoch [49/300] Completed - Loss D: 0.1966, loss G: 3.9222\n",
      "Epoch [54/300] Completed - Loss D: 0.1992, loss G: 4.2333\n",
      "Epoch [59/300] Completed - Loss D: 0.2460, loss G: 3.2909\n",
      "Epoch [64/300] Completed - Loss D: 0.1077, loss G: 3.2208\n",
      "Epoch [69/300] Completed - Loss D: 0.0726, loss G: 5.5236\n",
      "Epoch [74/300] Completed - Loss D: 0.2269, loss G: 3.7309\n",
      "Epoch [79/300] Completed - Loss D: 0.0482, loss G: 4.3589\n",
      "Epoch [84/300] Completed - Loss D: 0.1388, loss G: 4.5694\n",
      "Epoch [89/300] Completed - Loss D: 0.4239, loss G: 2.5208\n",
      "Epoch [94/300] Completed - Loss D: 0.0530, loss G: 4.5404\n",
      "Epoch [99/300] Completed - Loss D: 0.2185, loss G: 3.6406\n",
      "Epoch [104/300] Completed - Loss D: 0.2503, loss G: 6.3142\n",
      "Epoch [109/300] Completed - Loss D: 0.2926, loss G: 5.7523\n",
      "Epoch [114/300] Completed - Loss D: 0.0830, loss G: 5.5393\n",
      "Epoch [119/300] Completed - Loss D: 0.1358, loss G: 5.7148\n",
      "Epoch [124/300] Completed - Loss D: 0.4355, loss G: 2.9440\n",
      "Epoch [129/300] Completed - Loss D: 0.4119, loss G: 3.0959\n",
      "Epoch [134/300] Completed - Loss D: 0.5157, loss G: 4.5810\n",
      "Epoch [139/300] Completed - Loss D: 0.1101, loss G: 6.1230\n",
      "Epoch [144/300] Completed - Loss D: 0.0850, loss G: 5.5928\n",
      "Epoch [149/300] Completed - Loss D: 0.0356, loss G: 6.3147\n",
      "Epoch [154/300] Completed - Loss D: 0.1889, loss G: 4.6329\n",
      "Epoch [159/300] Completed - Loss D: 0.3205, loss G: 5.7709\n",
      "Epoch [164/300] Completed - Loss D: 0.1820, loss G: 4.7202\n",
      "Epoch [169/300] Completed - Loss D: 0.2852, loss G: 4.7874\n",
      "Epoch [174/300] Completed - Loss D: 0.2293, loss G: 5.1418\n",
      "Epoch [179/300] Completed - Loss D: 0.3122, loss G: 4.9008\n",
      "Epoch [184/300] Completed - Loss D: 0.0374, loss G: 5.9813\n",
      "Epoch [189/300] Completed - Loss D: 0.3753, loss G: 3.9278\n",
      "Epoch [194/300] Completed - Loss D: 0.3171, loss G: 4.2502\n",
      "Epoch [199/300] Completed - Loss D: 0.1070, loss G: 3.9949\n",
      "Epoch [204/300] Completed - Loss D: 0.1862, loss G: 4.8276\n",
      "Epoch [209/300] Completed - Loss D: 0.1269, loss G: 3.8622\n",
      "Epoch [214/300] Completed - Loss D: 0.5396, loss G: 4.7625\n",
      "Epoch [219/300] Completed - Loss D: 0.2743, loss G: 5.8426\n",
      "Epoch [224/300] Completed - Loss D: 0.3246, loss G: 3.8569\n",
      "Epoch [229/300] Completed - Loss D: 0.1510, loss G: 4.2734\n",
      "Epoch [234/300] Completed - Loss D: 0.4407, loss G: 4.5042\n",
      "Epoch [239/300] Completed - Loss D: 0.0798, loss G: 5.4424\n",
      "Epoch [244/300] Completed - Loss D: 0.2511, loss G: 3.6812\n",
      "Epoch [249/300] Completed - Loss D: 0.1202, loss G: 5.4932\n",
      "Epoch [254/300] Completed - Loss D: 0.1855, loss G: 3.5771\n",
      "Epoch [259/300] Completed - Loss D: 0.2068, loss G: 3.6742\n",
      "Epoch [264/300] Completed - Loss D: 0.1737, loss G: 5.0871\n",
      "Epoch [269/300] Completed - Loss D: 0.1304, loss G: 3.5781\n",
      "Epoch [274/300] Completed - Loss D: 0.1231, loss G: 4.5947\n",
      "Epoch [279/300] Completed - Loss D: 0.2117, loss G: 5.2366\n",
      "Epoch [284/300] Completed - Loss D: 0.4368, loss G: 4.8268\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs): \n",
    "    for batch_idx, (real, _) in enumerate(train_loader):\n",
    "        \n",
    "        real = real.view(-1, image_dim).to(device)  # Flatten the images into vectors\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        # Generate random noise as input for the generator\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        \n",
    "        # Generate fake images with the generator\n",
    "        fake = gen(noise)\n",
    "        \n",
    "        # Compute the discriminator losses on real images\n",
    "        disc_real = disc(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        \n",
    "        # Compute the discriminator losses on fake images\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        \n",
    "        # Combine losses for the discriminator\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        \n",
    "        # Update discriminator\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Update generator\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "\n",
    "\n",
    "    # After all batches are processed for the current epoch, check if it's time to print\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        with torch.no_grad():\n",
    "            fake = gen(fixed_noise).reshape(-1,1,192,192)\n",
    "            data = real.reshape(-1, 1, 192, 192)\n",
    "            \n",
    "            img_grid_real = torchvision.utils.make_grid(data[:16], normalize=True)\n",
    "            img_grid_fake = torchvision.utils.make_grid(fake[:16], normalize=True)\n",
    "\n",
    "            writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "            writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "        # The print statement has been moved outside of the inner loop, and the condition is changed to every 5 epochs\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] Completed - Loss D: {lossD:.4f}, loss G: {lossG:.4f}\")\n",
    "\n",
    "    # Increment the step after each epoch\n",
    "    step += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc5201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
