{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "263017f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f704ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fabe343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_csv, transform=None):\n",
    "        \n",
    "\n",
    "        self.labels_df = pd.read_csv(labels_csv)\n",
    "\n",
    "        self.label_map = {row[\"FeatID\"]: row[\"class\"] for index, row in self.labels_df.iterrows()}\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feat_id = list(self.label_map.keys())[idx]\n",
    "        img_name = f\"featID {feat_id}.png\"\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        label = self.label_map[feat_id]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad7e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56d03eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images'\n",
    "labels_csv = '/Users/karthik/AeruginosaWithClass.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c31bf8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa8945c",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c31f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "\n",
    "image_dim = 1*224*224\n",
    "\n",
    "n_class = 5 \n",
    "\n",
    "latent_dim = 112\n",
    "\n",
    "lr = 0.0002\n",
    "\n",
    "b1 = 0.5\n",
    "\n",
    "b2 = 0.999\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cefd69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e179801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009f1494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ab20102",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(image_directory, labels_csv, transform=transform)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for images, labels in data_loader:\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ed200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "709e6bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 2100\n",
      "Total labels: 5\n"
     ]
    }
   ],
   "source": [
    "total_images = len(dataset)\n",
    "total_labels = len(set(dataset.labels_df['class']))  \n",
    "\n",
    "print(f\"Total images: {total_images}\")\n",
    "print(f\"Total labels: {total_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c073582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7af0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 66\n"
     ]
    }
   ],
   "source": [
    "total_batches = len(data_loader)\n",
    "print(f\"Total batches: {total_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b5059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa054d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 has 32 images and 32 labels\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(data_loader, 1):\n",
    "    print(f\"Batch {i} has {len(images)} images and {len(labels)} labels\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe8823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8098be2b",
   "metadata": {},
   "source": [
    "**Creating a Loop over the data loader to get the labels in the first batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd38151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in the first batch:\n",
      "tensor([3, 1, 2, 0, 0, 1, 3, 2, 0, 0, 2, 1, 0, 2, 4, 2, 0, 2, 3, 0, 2, 4, 2, 1,\n",
      "        3, 1, 3, 0, 1, 3, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "first_batch_labels = next(iter(data_loader))[1] \n",
    "\n",
    "print(\"Labels in the first batch:\")\n",
    "print(first_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222f003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80d7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e3aab5d",
   "metadata": {},
   "source": [
    "**Generator Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "425ed754",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(n_class, n_class)\n",
    "\n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(latent_dim + n_class, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 1024)\n",
    "        self.fc5 = nn.Linear(1024, 1024)\n",
    "        self.fc6 = nn.Linear(1024, 2048)\n",
    "        self.fc7 = nn.Linear(2048, 2048)\n",
    "        self.fc8 = nn.Linear(2048, image_dim)\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        \n",
    "        # Concatenate label embedding and image to produce input\n",
    "        x = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.fc6(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.fc7(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "\n",
    "        x = self.fc8(x)\n",
    "        img = torch.tanh(x)\n",
    "        \n",
    "        img = img.view(img.size(0), image_dim)\n",
    "        return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a6a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e0cf120",
   "metadata": {},
   "source": [
    "**Discriminator Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f0124dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.label_embedding = nn.Embedding(n_class, n_class)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_class + image_dim, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        \n",
    "        # Concatenate label embedding and image to produce input\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), dim= -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257fc9ae",
   "metadata": {},
   "source": [
    "Combo 1 - 256 Layer 2 in D\n",
    "Combo 2 - 512 Layer 2 in D\n",
    "Combo 3 - add one small layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48f1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4161bbeb",
   "metadata": {},
   "source": [
    "**Optiminser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6206a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91894577",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a8e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69509d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ca46ce5",
   "metadata": {},
   "source": [
    "**Tensorboard Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e554805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter \n",
    "\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc6969",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85217c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(16, latent_dim, device=device)  \n",
    "fixed_labels = torch.randint(0, n_class, (16,), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f3669bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FloatTensor = torch.FloatTensor\n",
    "LongTensor = torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(data_loader):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = FloatTensor(batch_size, 1).fill_(1.0)\n",
    "        fake = FloatTensor(batch_size, 1).fill_(0.0)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs.type(FloatTensor)\n",
    "        labels = labels.type(LongTensor)\n",
    "\n",
    "        # Training Generator\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim)))\n",
    "        gen_labels = LongTensor(np.random.randint(0, n_class, batch_size))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity = discriminator(gen_imgs, gen_labels)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Training Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        validity_real = discriminator(real_imgs, labels)\n",
    "        d_real_loss = adversarial_loss(validity_real, valid)\n",
    "\n",
    "        # Loss for fake images\n",
    "        validity_fake = discriminator(gen_imgs.detach(), gen_labels)\n",
    "        d_fake_loss = adversarial_loss(validity_fake, fake)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "\n",
    "        print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, n_epochs, i, len(data_loader), d_loss.item(), g_loss.item())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64506a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "710f31c1",
   "metadata": {},
   "source": [
    "**To Generate Specific Sample Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8165ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define the specific label and the number of images you want to generate\n",
    "specific_label = 0\n",
    "num_images = 16  # Example: generate 5 images\n",
    "\n",
    "# Assuming you're using a GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate noise vectors\n",
    "noise = torch.randn(num_images, latent_dim).to(device)\n",
    "\n",
    "# Create label tensor (all elements are the specific label)\n",
    "labels = torch.full((num_images,), specific_label, dtype=torch.long).to(device)\n",
    "\n",
    "# Generate images\n",
    "with torch.no_grad():\n",
    "    generated_images = generator(noise, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3b4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbd79ad3",
   "metadata": {},
   "source": [
    "**To Visualise the Generated Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming generated_images is a batch of images\n",
    "num_images = 16\n",
    "rows = 4\n",
    "cols = 4  # 4x4 grid for 16 images\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
    "\n",
    "for i, img in enumerate(generated_images):\n",
    "    ax = axes[i // cols, i % cols]  # Determine the row and column\n",
    "\n",
    "    # Reshape the image from (50176,) to (224, 224) and normalize it to [0, 1]\n",
    "    img = img.view(224, 224)  # Reshape\n",
    "    img = (img + 1) / 2       # Normalize\n",
    "    img = img.clamp(0, 1)\n",
    "    img = img.cpu()\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(img.numpy(), cmap='gray')\n",
    "    ax.axis('off')  # Hide axes\n",
    "\n",
    "# Ensure there are no empty plots if there are fewer than 16 images\n",
    "for i in range(len(generated_images), rows * cols):\n",
    "    axes[i // cols, i % cols].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e435d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cc61753",
   "metadata": {},
   "source": [
    "- 8 Layer G & D \n",
    "- 8 Layer G & 7 Layer D\n",
    "- Tuning 8 Layer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5bd502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
