{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b85debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e3abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab06f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_csv, transform=None):\n",
    "        \n",
    "\n",
    "        self.labels_df = pd.read_csv(labels_csv)\n",
    "\n",
    "        self.label_map = {row[\"FeatID\"]: row[\"class\"] for index, row in self.labels_df.iterrows()}\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feat_id = list(self.label_map.keys())[idx]\n",
    "        img_name = f\"featID {feat_id}.png\"\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        label = self.label_map[feat_id]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e65014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389573f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = '/Users/karthik/GANS/4by4-TOPO-24X224/renamed_images'\n",
    "labels_csv = '/Users/karthik/AeruginosaWithClass.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bde21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fcd7e63",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e66a7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "\n",
    "image_dim = 1*224*224\n",
    "\n",
    "n_class = 5 \n",
    "\n",
    "latent_dim = 100\n",
    "\n",
    "lr = 0.0002\n",
    "\n",
    "b1 = 0.5\n",
    "\n",
    "b2 = 0.999\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d527309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675c6012",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d7e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11304312",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(image_directory, labels_csv, transform=transform)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for images, labels in data_loader:\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec0baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a2a8fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 2100\n",
      "Total labels: 5\n"
     ]
    }
   ],
   "source": [
    "total_images = len(dataset)\n",
    "total_labels = len(set(dataset.labels_df['class']))  \n",
    "\n",
    "print(f\"Total images: {total_images}\")\n",
    "print(f\"Total labels: {total_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced7f515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d57c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 33\n"
     ]
    }
   ],
   "source": [
    "total_batches = len(data_loader)\n",
    "print(f\"Total batches: {total_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b2ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8de967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 has 64 images and 64 labels\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(data_loader, 1):\n",
    "    print(f\"Batch {i} has {len(images)} images and {len(labels)} labels\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced7415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0a4e3fb",
   "metadata": {},
   "source": [
    "**Creating a Loop over the data loader to get the labels in the first batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03b359c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in the first batch:\n",
      "tensor([1, 1, 3, 2, 0, 3, 0, 0, 1, 1, 1, 0, 2, 0, 3, 3, 0, 3, 2, 0, 3, 0, 0, 0,\n",
      "        3, 1, 1, 4, 2, 1, 0, 0, 1, 3, 0, 0, 3, 4, 1, 3, 0, 3, 0, 1, 1, 1, 0, 3,\n",
      "        2, 0, 3, 0, 0, 4, 3, 1, 1, 3, 2, 1, 0, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "first_batch_labels = next(iter(data_loader))[1] \n",
    "\n",
    "print(\"Labels in the first batch:\")\n",
    "print(first_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f7d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e89552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1563e37",
   "metadata": {},
   "source": [
    "**Generator Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1972c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(n_class, n_class)\n",
    "\n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(latent_dim + n_class, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.fc4 = nn.Linear(512, 1024)\n",
    "        self.fc5 = nn.Linear(1024, image_dim)\n",
    "\n",
    "        # Define the batch normalization layers\n",
    "        self.batch_norm2 = nn.BatchNorm1d(256, 0.8)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(512, 0.8)\n",
    "        self.batch_norm4 = nn.BatchNorm1d(1024, 0.8)\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        \n",
    "        # Concatenate label embedding and image to produce input\n",
    "        x = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        img = torch.tanh(x)\n",
    "        img = img.view(img.size(0), image_dim)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614e3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4ef8e7f",
   "metadata": {},
   "source": [
    "**Discriminator Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6154ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.label_embedding = nn.Embedding(n_class, n_class)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_class + image_dim, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), dim=-1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf62ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4debe461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7abf8fb0",
   "metadata": {},
   "source": [
    "**Optiminser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3bb6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = torch.nn.MSELoss()\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7102b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc8685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d80537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "441df607",
   "metadata": {},
   "source": [
    "**Tensorboard Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e497c29f",
   "metadata": {},
   "source": [
    "from torch.utils.tensorboard import SummaryWriter \n",
    "\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a08aed",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d267a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FloatTensor = torch.FloatTensor\n",
    "LongTensor = torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76c269aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/33] [D loss: 0.494994] [G loss: 0.929005]\n",
      "[Epoch 0/200] [Batch 1/33] [D loss: 2.778057] [G loss: 0.878239]\n",
      "[Epoch 0/200] [Batch 2/33] [D loss: 0.280956] [G loss: 0.863225]\n",
      "[Epoch 0/200] [Batch 3/33] [D loss: 0.107295] [G loss: 0.843420]\n",
      "[Epoch 0/200] [Batch 4/33] [D loss: 0.235785] [G loss: 0.823319]\n",
      "[Epoch 0/200] [Batch 5/33] [D loss: 0.083146] [G loss: 0.813332]\n",
      "[Epoch 0/200] [Batch 6/33] [D loss: 0.123867] [G loss: 0.787185]\n",
      "[Epoch 0/200] [Batch 7/33] [D loss: 0.083375] [G loss: 0.755836]\n",
      "[Epoch 0/200] [Batch 8/33] [D loss: 0.093909] [G loss: 0.731295]\n",
      "[Epoch 0/200] [Batch 9/33] [D loss: 0.063474] [G loss: 0.705369]\n",
      "[Epoch 0/200] [Batch 10/33] [D loss: 0.057049] [G loss: 0.662764]\n",
      "[Epoch 0/200] [Batch 11/33] [D loss: 0.054767] [G loss: 0.638120]\n",
      "[Epoch 0/200] [Batch 12/33] [D loss: 0.065212] [G loss: 0.608088]\n",
      "[Epoch 0/200] [Batch 13/33] [D loss: 0.068332] [G loss: 0.590467]\n",
      "[Epoch 0/200] [Batch 14/33] [D loss: 0.069035] [G loss: 0.592488]\n",
      "[Epoch 0/200] [Batch 15/33] [D loss: 0.063001] [G loss: 0.580010]\n",
      "[Epoch 0/200] [Batch 16/33] [D loss: 0.058148] [G loss: 0.589807]\n",
      "[Epoch 0/200] [Batch 17/33] [D loss: 0.068551] [G loss: 0.627381]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m adversarial_loss(validity, valid)\n\u001b[1;32m     28\u001b[0m g_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 29\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Training Discriminator\u001b[39;00m\n\u001b[1;32m     32\u001b[0m optimizer_D\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     adam(\n\u001b[1;32m    164\u001b[0m         params_with_grad,\n\u001b[1;32m    165\u001b[0m         grads,\n\u001b[1;32m    166\u001b[0m         exp_avgs,\n\u001b[1;32m    167\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    168\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    169\u001b[0m         state_steps,\n\u001b[1;32m    170\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    171\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    172\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    173\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    174\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    175\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    176\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    177\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    178\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    179\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    180\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    181\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    182\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m func(params,\n\u001b[1;32m    312\u001b[0m      grads,\n\u001b[1;32m    313\u001b[0m      exp_avgs,\n\u001b[1;32m    314\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    315\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    316\u001b[0m      state_steps,\n\u001b[1;32m    317\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    318\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    319\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    320\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    321\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    322\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    323\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    324\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    325\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    326\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    327\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:385\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    384\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 385\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    388\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(data_loader):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = FloatTensor(batch_size, 1).fill_(1.0)\n",
    "        fake = FloatTensor(batch_size, 1).fill_(0.0)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs.type(FloatTensor)\n",
    "        labels = labels.type(LongTensor)\n",
    "\n",
    "        # Training Generator\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim)))\n",
    "        gen_labels = LongTensor(np.random.randint(0, n_class, batch_size))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity = discriminator(gen_imgs, gen_labels)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Training Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        validity_real = discriminator(real_imgs, labels)\n",
    "        d_real_loss = adversarial_loss(validity_real, valid)\n",
    "\n",
    "        # Loss for fake images\n",
    "        validity_fake = discriminator(gen_imgs.detach(), gen_labels)\n",
    "        d_fake_loss = adversarial_loss(validity_fake, fake)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, n_epochs, i, len(data_loader), d_loss.item(), g_loss.item())\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf02bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
